transformers[sentencepiece]==4.35.0
huggingface_hub==0.16.4
optimum[onnxruntime]==1.14.0
safetensors==0.4.0
Flask==2.3.3
Flask-SocketIO==5.3.2
Werkzeug==2.3.7
python-socketio==5.7.2
requests
torch == 2.0.*
flask-cloudflared==0.0.10
flask-ngrok
flask-cors
eventlet==0.33.3
dnspython==2.2.1
lupa==1.10
markdown
bleach==4.1.0
protobuf
accelerate==0.24.1
flask-session==0.5.0
marshmallow>=3.13
apispec-webframeworks
loguru
termcolor
git+https://github.com/VE-FORBRYDERNE/mkultra
Pillow
diffusers
psutil
ansi2html
flask_compress
ijson
bitsandbytes==0.40.0.post4; sys_platform == 'linux'
https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.0.post4-py3-none-win_amd64.whl; sys_platform == 'win32'
ftfy
pydub
pytest==7.2.2
pytest-html==3.2.0
pytest-metadata==2.0.4
requests-mock==1.10.0
git+https://github.com/0cc4m/hf_bleeding_edge/
einops
peft==0.6.0
scipy
auto-gptq==0.5.0
windows-curses; sys_platform == 'win32'
pynvml
https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.0/flash_attn-2.3.0+cu118torch2.0cxx11abiFALSE-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux' and python_version == '3.10'
https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.0/flash_attn-2.3.0+cu118torch2.0cxx11abiFALSE-cp38-cp38-linux_x86_64.whl; sys_platform == 'linux' and python_version == '3.8'
xformers==0.0.21
omegaconf
